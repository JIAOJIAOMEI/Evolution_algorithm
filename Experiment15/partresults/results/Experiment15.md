# Comments

The whole run is not over yet, and this current report is generated based on the results of 2394/2880 already completed. We have three algorithms, 2394/3=798, with the same parameters except for the algorithms ["baseline", "baldwin", "lamarck].

# Parameter combinations

At the time of TDK, we have 8 unique parameter combinations, as follows

|      | num_generations | mutation_rate | num_individuals | crossover_rate | mutation_type | crossover_type          | local_search_rate | local_search_type | search_radius | threshold |
| ---- | --------------- | ------------- | --------------- | -------------- | ------------- | ----------------------- | ----------------- | ----------------- | ------------- | --------- |
| 590  | 1000000         | 0.04          | 100             | 0.5            | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.1           | 0.0001    |
| 579  | 1000000         | 0.02          | 200             | 0.6            | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.1           | 0.0001    |
| 588  | 1000000         | 0.04          | 100             | 0.6            | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.1           | 0.0001    |
| 589  | 1000000         | 0.04          | 100             | 0.7            | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.1           | 0.0001    |
| 569  | 1000000         | 0.02          | 200             | 0.5            | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.1           | 0.0001    |
| 558  | 1000000         | 0.02          | 100             | 0.6            | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.1           | 0.0001    |
| 542  | 1000000         | 0.01          | 200             | 0.5            | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.1           | 0.0001    |
| 562  | 1000000         | 0.02          | 100             | 0.7            | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.1           | 0.0001    |

The function we tested at that time of TDK was of 50 dimensions.

Later we added two more parameters, generation gap and selection method.

```python
gg = [0.01, 0.2, 0.5, 0.8, 0.99] #5
selection_method = ["SSGA", "sorted_selection_part", "sorted_selection_all", "roulette_Wheel_Select"] #4
```

Finally, the function and algorithm parameters are added,

```python
fitness_function = [1, 5, 7, 8, 10, 13] #6
algorithm = ["Baseline", "Lamarck", "Baldwin"] #3
```

So the overall combination of parameters this time is 8X5X4X6X3=2880.(This time dim=100.)

# Recall the results of TDK

At TDK, the number of generations is the same for all three algorithms, with SSGA using F.() once and Lamarck and Baldwin using F.() twice in each generation.

The graph below is generated by me based on TDK data, with a total of 20 parameter combinations. What I want to express here is that although the quality of the final solutions of the three algorithms is more or less the same level, Baldwin and Lamarck used double the number of evaluations to reach the same level as SSGA.

![experiment15use](experiment15use.png)

The following graph is generated by combining only 8 unique parameters, again with TDK data. The chart above is TDK data with 20 parameters, which has some redundancy, and now this chart has only 8 unique parameters. The point I am trying to make here is that Baldwin and Lamarck use double the number of evaluations, but do not completely outperform SSGA, and Lamarck is sometimes even inferior to Baldwin, e.g. F8.

![experiment15use8unique](experiment15use8unique.png)

# results of experiment15(part)

In Experiment15, the number of evaluations (budget) is the same for all three algorithms, with SSGA using F.() once and Lamarck and Baldwin using F.() twice in each generation. This means that if SSGA iterates 10 times, then Lamarck and Baldwin can only iterate 5 times.

dim=100, budget = 10,000*dim

## Crossover rate

![crossover_rate](crossover_rate.png)

## Mutation rate

![mutation_rate](mutation_rate.png)

## Generation gap

![gg](gg.png)

## Selection method

![selection_method](selection_method.png)

## Conclusion

Overall, SSGA is better than Baldwin and Baldwin is better than Lamarck. 

I think there are two reasons for this. The biggest reason is, of course, that Baldwin and Lamarck have only half the number of iterations of baseline, because the condition of number of evaluations has to be satisfied the same. 

The second reason is that in TDK, the number of generations is the same for all three algorithms, which fundamentally ensures that Baldwin and Lamarck produce results that are not much worse than SSGA, or at least will be SAME level if the local search procedure is not useful. If there is no better solution, then one's genotype are used as one's phenotype. This strategy, with the same number of generations and local search not producing a better solution, ensures that the quality of the final solution produced by the three algorithms is similar. 

We use **local search type: uniform; local search rate: 0.5, and local search radius: 0.1**, which make it difficult to produce better solutions than genotype. We chose this set of parameters because it can bring the multimodal functions out of the local minimas and then have the chance to find the global minimas, which is clearly the case for functions 15, 21, 22 and 23. This set of parameters can take multimodal functions out of local minimas if they are trapped there, but is meaningless for unimodal functions (1,5,7,etc).

Some time before TDK, we found that the last few multimodal functions could not find the minimum value because they were stuck in local minima. If the initial position is good, it can find the global minima very quickly, but once it enters the local minima, then it will always be stuck in the local minima and cannot escape.

We used Euclidean distance to measure the similarity of the entire population when stuck in lcoal minima. First we use the Euclidean distance to calculate the distance between the phenotype of any individual and the optimal individual, and then sum up these results, which is the similarity of the entire population. (it can reach 0, but the threshold=0.0001 used later) if the Euclidean similarity of the population is smaller than this threshold for some continuous iterations, then the program will terminate early, one of the termination conditions.

This is also in line with the view of biological evolution. We define what is good and what is excellent, that is, when the phenotype is brought into the test function, the smaller the solution obtained, the better the individual.**We guide the direction of evolution.** All individuals will aim at the best individual in the population and adjust their genes, otherwise they will be eliminated. **Evolution is not just the best individuals in the population evolving, but other individuals are also evolving.** **What I mean is that if the best individuals find the global minima, then the remaining individuals will also find the global minima very quickly.**

But what if the best individual gets stuck in the local minima and can't get out? When the best individual in the population finds a local minima, no local search procedure can help the best individual leave the local minima, because the local minima is the best position in the its local surrounding. Other individuals will also quickly find this local minima, and then the entire population will be stuck here. At this time, what it needs is not a local search procedure, but a jump. That's why we used the parameter :**local search type: uniform; local search rate: 0.5, and local search radius: 0.1**. When the phenotype is generated based on the genotype, each gene has a probability of 0.5 to mutate. If there are 50 genes, it means that about 25 genes will change. And the local search radius determines the variation range of unifrom local search, **0.1X domain**, it is a large range. This local search paraemter set ia able to cause a "jump" on the fitness landscape.

Finally, let me explain why this set of parameters is difficult to produce better solutions than genotype. You now have 50 dimensions of values, and then you need to change the values of 25 dimensions, because local search rate=0.5, maybe there is some progress in 13 dimensions, but there is some regression in 12 of them. In the end, the overall progress or regression is very difficult to control. **If the dimension increases, the difficulty of producing better solutions will increase greatly.**

In general, the number of evaluations of Baldwin and Lamarck is half of the baseline, and the local search procedure is meaningless for unimodal functions (such as 1, 5, 7, etc. of experiment15), so overall, SSGA is the best. 

As to why Baldwin and Lamarck are so far apart, I need to think some more about that.

Last but not least, gg are [0.01, 0.2, 0.5, 0.8, 0.99],**the middle three parameters are better than 0.01 and 0.99.**I personally think 0.8 is the best.

selection_method are ['SSGA', 'sorted_selection_part', 'sorted_selection_all', 'roulette_Wheel_Select'], **'sorted_selection_part'>'sorted_selection_all'>'SSGA'>'roulette_Wheel_Select'**

Also, it should be mentioned that mutation_rate has not changed, but the dimensionality has been increased from 50 to 100, which means that the difficulty of the task has been upgraded, but the ability to generate new genes has not changed, which will slow down the convergence rate to some extent.

**The reason is also very simple, assuming mutation_rate = 0.04, in the case of dimension = 50, it only needs to ensure progress in 2 dimensions to produce better solutions, but if dimension = 100, it needs to ensure progress in 4 dimensions , to produce better solutions.**