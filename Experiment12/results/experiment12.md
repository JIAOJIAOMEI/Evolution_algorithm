# Remarks

This experiment runs 8 parameter combinations for first 13 functions with 20 times run. The budget used for each algorithm is 50,000.  The dimension of each function is 400.

- The reason why choosing 8 parameter combinations is that we only have 8 unique paramter combinations. At the time we chose 20 parameter combinations, we had a parameter called "range_mutation", each parameter combination was different at that time. But later we did not use "range_mutation" any more, and instead, we started to use another parameter which is search radius R. R is the same for all parameter combinations. And this leads to the decrease of number of parameter combinations. I found this because due to the review's question for TDK conference. So in this run, I dropped duplicate parameter combinations. And now we only have 8 unique parameter combinations.
- The reason why choosing first 13 functions is that only the number of dimensions of first 13 functions can be increased. Other functions' dimensions are fixed.
- The following result does not contains F2, because the best solution of each algorithm with 50,000 budget is ==INF==.(too large)
- In order to achieve a better convergence rate, I decreased R=0.1 to R=0.005. A large R can help the population jump out of the local minima for multimodal functions, while a small R can help unimodal functions converge faster. I think later we can increase "mutation_rate", because we already increased the dimension. Meanwhile, we should decrease the local search rate, current local search rate= 0.5(same as previous), this is hard for a local search procedure to produce a better solution because it means that it should make some improvements over half of dimensions (400*0.5=200), then a better solution(phenotype) is generated, otherwise the genotype is used as phenotype(in case no improvement is made based on genotype).

|      | iterations | mutation_rate | num_individuals | crossover_probability | Mutation_type | Crossover_type          | local_search_rate | Local_search_type | R     | Budget |
| :--- | ---------- | ------------- | --------------- | --------------------- | ------------- | ----------------------- | ----------------- | :---------------- | ----- | ------ |
| 590  | 1000000    | 2/D           | 100             | 0.5                   | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.005 | 50000  |
| 579  | 1000000    | 1/D           | 200             | 0.6                   | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.005 | 50000  |
| 588  | 1000000    | 2/D           | 100             | 0.6                   | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.005 | 50000  |
| 589  | 1000000    | 2/D           | 100             | 0.7                   | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.005 | 50000  |
| 569  | 1000000    | 1/D           | 200             | 0.5                   | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.005 | 50000  |
| 558  | 1000000    | 1/D           | 100             | 0.6                   | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.005 | 50000  |
| 542  | 1000000    | 0.5/D         | 200             | 0.5                   | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.005 | 50000  |
| 562  | 1000000    | 1/D           | 100             | 0.7                   | Normal        | Probabilistic_crossover | 0.5               | Uniform           | 0.005 | 50000  |

# Results

Abs distance is *abs |final solution â€“ global minimum|*. The following pciture shows the sum of abs distance generated by 20 runs for first 13 functions except F2.

![distance](distance.png)



For each function and each parameter combination, we have 20 runs, and this means we have 160 final solutions for each function and 8 parameter combinations. The 3 algorithms produce 480 solutions in total. Each boxen is generated based on 160 solutions, but these 160 solutions are normalized(max min normalization) based on all 480 solutions so that they can be examined on the same scale. Also, they are generated based on same budget.

![final](final.png)



# Conclusion

- On F1, F3, F4, F5, F6, F7, F11, F12 and F13 (9 functions), Lamarckian algorithm is obviously better than the other two, as one can see that the box for Lamarckian algorithm is noticeably lower. SSGA is second best and Baldwinian algorithm is third.
- On F8, F9 and F10 (3 functions), SSGA is slightly better than Lamarckian algorithm because the box for SSGA is a little bit lower than the box for Lamarckian algorithm. The Baldwinian algorithm produces poor results.

